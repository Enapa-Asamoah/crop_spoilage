{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Spoilage Prediction - Machine Learning Pipeline\n",
    "\n",
    "This notebook develops a machine learning pipeline to predict crop spoilage conditions in Ghana using environmental data.\n",
    "\n",
    "## Project Overview\n",
    "- **Regression Task**: Predict spoilage time in days\n",
    "- **Classification Task**: Assess spoilage risk level (low, medium, high)\n",
    "- **Data**: ~5,000 samples with environmental variables for common Ghanaian crops\n",
    "- **Models**: Random Forest Regressor and Classifier with hyperparameter tuning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"ghana_crop_spoilage_dataset.csv\")\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print(\"Column Information:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistics and Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing_vals = df.isnull().sum()\n",
    "print(missing_vals[missing_vals > 0] if missing_vals.sum() > 0 else \"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables analysis\n",
    "print(\"Crop Types Distribution:\")\n",
    "print(df['crop'].value_counts())\n",
    "print(\"\\nSpoilage Risk Distribution:\")\n",
    "print(df['spoilage_risk'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode crop type\n",
    "le = LabelEncoder()\n",
    "df[\"crop_encoded\"] = le.fit_transform(df[\"crop\"])\n",
    "\n",
    "# Save label encoder for future uses\n",
    "joblib.dump(le, \"crop_label_encoder_trial.pkl\")\n",
    "\n",
    "print(\"Crop Encoding Mapping:\")\n",
    "crop_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "for crop, code in crop_mapping.items():\n",
    "    print(f\"{crop}: {code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "features = [\"temperature\", \"humidity\", \"moisture\", \"crop_encoded\"]\n",
    "X = df[features]\n",
    "y_reg = df[\"spoilage_days\"]\n",
    "y_clf = df[\"spoilage_risk\"]      \n",
    "\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"Regression target: spoilage_days\")\n",
    "print(f\"Classification target: spoilage_risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df[features + [\"spoilage_days\"]].corr()\n",
    "print(\"Correlation with spoilage_time_days:\")\n",
    "spoilage_time_corr = correlation_matrix[\"spoilage_days\"].sort_values(ascending=False)\n",
    "print(spoilage_time_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance of correlations\n",
    "print(\"Correlation significance tests:\")\n",
    "print(\"*** p<0.001, ** p<0.01, * p<0.05\")\n",
    "print(\"-\" * 40)\n",
    "for feature in features:\n",
    "    corr_coef, p_value = pearsonr(df[feature], df[\"spoilage_days\"])\n",
    "    significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"\"\n",
    "    print(f\"{feature:15}: r={corr_coef:6.3f}, p={p_value:.3f} {significance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
    "fig.suptitle('Crop Spoilage Dataset Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribution of spoilage time\n",
    "axes[0, 0].hist(df['spoilage_days'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Spoilage Time (Days)')\n",
    "axes[0, 0].set_xlabel('Days')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df['spoilage_days'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {df[\"spoilage_days\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Spoilage risk distribution\n",
    "spoilage_counts = df['spoilage_risk'].value_counts()\n",
    "colors = ['green', 'orange', 'red']\n",
    "bars = axes[0, 1].bar(spoilage_counts.index, spoilage_counts.values, color=colors)\n",
    "axes[0, 1].set_title('Spoilage Risk Distribution')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "for bar, count in zip(bars, spoilage_counts.values):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20, \n",
    "                    str(count), ha='center', va='bottom')\n",
    "\n",
    "# 3. Correlation heatmap\n",
    "corr_matrix = df[features + [\"spoilage_days\"]].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, ax=axes[1, 0], cbar_kws={'label': 'Correlation Coefficient'})\n",
    "axes[1, 0].set_title('Feature Correlation Heatmap')\n",
    "\n",
    "# 4. Spoilage time by crop type\n",
    "df.boxplot(column='spoilage_days', by='crop', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Spoilage Time by Crop Type')\n",
    "axes[1, 1].set_xlabel('Crop Type')\n",
    "axes[1, 1].set_ylabel('Spoilage Time (Days)')\n",
    "plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# 5. Temperature vs Spoilage Time (colored by humidity)\n",
    "scatter = axes[2, 0].scatter(df['temperature'], df['spoilage_days'], \n",
    "                           c=df['humidity'], cmap='viridis', alpha=0.6)\n",
    "axes[2, 0].set_title('Temperature vs Spoilage Time (colored by humidity)')\n",
    "axes[2, 0].set_xlabel('Temperature (°C)')\n",
    "axes[2, 0].set_ylabel('Spoilage Time (Days)')\n",
    "cbar = plt.colorbar(scatter, ax=axes[2, 0])\n",
    "cbar.set_label('Humidity (%)')\n",
    "\n",
    "#6. Deviation score impact\n",
    "axes[2, 1].scatter(df['deviation_score'], df['spoilage_days'], alpha=0.6, color='purple')\n",
    "axes[2, 1].set_title('Deviation Score vs Spoilage Time')\n",
    "axes[2, 1].set_xlabel('Deviation Score')\n",
    "axes[2, 1].set_ylabel('Spoilage Time (Days)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for regression and classification\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_clf, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size (regression): {X_train_reg.shape[0]}\")\n",
    "print(f\"Test set size (regression): {X_test_reg.shape[0]}\")\n",
    "print(f\"Training set size (classification): {X_train_clf.shape[0]}\")\n",
    "print(f\"Test set size (classification): {X_test_clf.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Regression Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression model and hyperparameters\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "reg_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "print(\"Starting regression model training with GridSearchCV...\")\n",
    "print(f\"Parameter combinations to test: {len(reg_params['n_estimators']) * len(reg_params['max_depth']) * len(reg_params['min_samples_split']) * len(reg_params['min_samples_leaf'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regression model\n",
    "grid_reg = GridSearchCV(regressor, reg_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "grid_reg.fit(X_train_reg, y_train_reg)\n",
    "best_reg = grid_reg.best_estimator_\n",
    "\n",
    "print(\"Regression model training completed!\")\n",
    "print(f\"Best parameters: {grid_reg.best_params_}\")\n",
    "print(f\"Best CV score: {-grid_reg.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate regression model\n",
    "y_pred_reg = best_reg.predict(X_test_reg)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "rmse = root_mean_squared_error(y_test_reg, y_pred_reg)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"REGRESSION MODEL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.3f} days\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.3f} days\")\n",
    "print(f\"R² Score: {r2:.3f}\")\n",
    "print(f\"Model explains {r2*100:.1f}% of the variance in spoilage time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for regression\n",
    "feature_importance_reg = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': best_reg.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Regression):\")\n",
    "print(feature_importance_reg)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_reg['feature'], feature_importance_reg['importance'])\n",
    "plt.title('Feature Importance - Regression Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Classification Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification model and hyperparameters\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "clf_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "print(\"Starting classification model training with GridSearchCV...\")\n",
    "print(f\"Parameter combinations to test: {len(clf_params['n_estimators']) * len(clf_params['max_depth']) * len(clf_params['min_samples_split']) * len(clf_params['min_samples_leaf'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classification model\n",
    "grid_clf = GridSearchCV(classifier, clf_params, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_clf.fit(X_train_clf, y_train_clf)\n",
    "best_clf = grid_clf.best_estimator_\n",
    "\n",
    "print(\"Classification model training completed!\")\n",
    "print(f\"Best parameters: {grid_clf.best_params_}\")\n",
    "print(f\"Best CV score: {grid_clf.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classification model\n",
    "y_pred_clf = best_clf.predict(X_test_clf)\n",
    "accuracy = accuracy_score(y_test_clf, y_pred_clf)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"CLASSIFICATION MODEL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy: {accuracy:.3f} ({accuracy*100:.1f}% correct predictions)\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test_clf, y_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for classification\n",
    "feature_importance_clf = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': best_clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Classification):\")\n",
    "print(feature_importance_clf)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_clf['feature'], feature_importance_clf['importance'])\n",
    "plt.title('Feature Importance - Classification Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "joblib.dump(best_reg, \"spoilage_time_regressor_enhanced.pkl\")\n",
    "joblib.dump(best_clf, \"spoilage_risk_classifier_enhanced.pkl\")\n",
    "joblib.dump(le, \"crop_label_encoder.pkl\")\n",
    "\n",
    "print(\"Models saved successfully!\")\n",
    "print(\"Files created:\")\n",
    "print(\"- spoilage_time_regressor_enhanced.pkl\")\n",
    "print(\"- spoilage_risk_classifier_enhanced.pkl\")\n",
    "print(\"- crop_label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction for a new sample\n",
    "sample_data = {\n",
    "    'temperature': 28.5,\n",
    "    'humidity': 65.0,\n",
    "    'moisture': 12.0,\n",
    "    'crop_encoded': 0 \n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame([sample_data])\n",
    "predicted_days = best_reg.predict(sample_df)[0]\n",
    "predicted_risk = best_clf.predict(sample_df)[0]\n",
    "predicted_risk_proba = best_clf.predict_proba(sample_df)[0]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"PREDICTION EXAMPLE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Input conditions:\")\n",
    "for key, value in sample_data.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"\\nPredictions:\")\n",
    "print(f\"  Spoilage time: {predicted_days:.1f} days\")\n",
    "print(f\"  Risk level: {predicted_risk}\")\n",
    "print(f\"  Risk probabilities: {dict(zip(best_clf.classes_, predicted_risk_proba))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Dataset Overview:\")\n",
    "print(f\"  - {len(df):,} samples across {len(df['crop'].unique())} crop types\")\n",
    "print(f\"  - Average spoilage time: {df['spoilage_days'].mean():.1f} ± {df['spoilage_days'].std():.1f} days\")\n",
    "print(f\"  - Temperature range: {df['temperature'].min():.1f}°C - {df['temperature'].max():.1f}°C\")\n",
    "print(f\"  - Humidity range: {df['humidity'].min():.1f}% - {df['humidity'].max():.1f}%\")\n",
    "\n",
    "print(f\"\\nKey Predictors:\")\n",
    "print(f\"  - Strongest regression predictor: {feature_importance_reg.iloc[0]['feature']}\")\n",
    "print(f\"  - Strongest classification predictor: {feature_importance_clf.iloc[0]['feature']}\")\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  - Regression R²: {r2:.3f} (explains {r2*100:.1f}% of variance)\")\n",
    "print(f\"  - Classification Accuracy: {accuracy:.3f} ({accuracy*100:.1f}% correct predictions)\")\n",
    "\n",
    "print(f\"\\nBusiness Impact:\")\n",
    "print(f\"  - Average prediction error: ±{mae:.1f} days\")\n",
    "print(f\"  - System can classify risk levels with {accuracy*100:.1f}% accuracy\")\n",
    "print(f\"  - Models ready for API integration and real-time monitoring\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db_chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
